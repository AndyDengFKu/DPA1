{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdtSIx8TVNOOqfI6l0klSc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndyDengFKu/DPA1/blob/main/DPL_A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import accuracy_score\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MfEQ-R1_mklG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "113216e8-ee74-4db6-c212-da9a064c2b99"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from LIBSVM format\n",
        "def load_libsvm_format(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    data = []\n",
        "    labels = []\n",
        "    max_feature_index = 0\n",
        "\n",
        "    for line in lines:\n",
        "        items = line.strip().split()\n",
        "        labels.append(int(items[0]))\n",
        "\n",
        "        features = {}\n",
        "        for item in items[1:]:\n",
        "            index, value = item.split(\":\")\n",
        "            index = int(index)\n",
        "            features[index] = float(value)\n",
        "            if index > max_feature_index:\n",
        "                max_feature_index = index\n",
        "\n",
        "        data.append(features)\n",
        "\n",
        "    # Convert to matrix format\n",
        "    matrix_data = np.zeros((len(data), max_feature_index))\n",
        "    for i, row in enumerate(data):\n",
        "        for index, value in row.items():\n",
        "            matrix_data[i][index - 1] = value\n",
        "\n",
        "    return np.array(matrix_data), np.array(labels)\n",
        "\n",
        "# Ensure that X_train and X_val have the same number of features\n",
        "def align_features(X_train, X_val):\n",
        "    num_features_train = X_train.shape[1]\n",
        "    num_features_val = X_val.shape[1]\n",
        "\n",
        "    if num_features_train > num_features_val:\n",
        "        # Add missing columns to X_val\n",
        "        missing_cols = np.zeros((X_val.shape[0], num_features_train - num_features_val))\n",
        "        X_val = np.hstack((X_val, missing_cols))\n",
        "\n",
        "    elif num_features_train < num_features_val:\n",
        "        # Add missing columns to X_train\n",
        "        missing_cols = np.zeros((X_train.shape[0], num_features_val - num_features_train))\n",
        "        X_train = np.hstack((X_train, missing_cols))\n",
        "\n",
        "    return X_train, X_val\n",
        "\n",
        "\n",
        "# Load training data\n",
        "X_train, y_train = load_libsvm_format(\"/content/drive/MyDrive/Colab Notebooks/DeepLearning/A1/a1.txt\")\n",
        "\n",
        "# Load validation data\n",
        "X_val, y_val = load_libsvm_format(\"/content/drive/MyDrive/Colab Notebooks/DeepLearning/A1/a1a.txt\")\n",
        "\n",
        "# Align the features of training and validation data\n",
        "X_train_aligned, X_val_aligned = align_features(X_train, X_val)\n",
        "\n",
        "print(f\"Training data shape: {X_train_aligned.shape}\")\n",
        "print(f\"Validation data shape: {X_val_aligned.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH2KYvlUovAD",
        "outputId": "fa796465-1de8-4df7-baf7-05643a8e33a1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (1605, 123)\n",
            "Validation data shape: (30956, 123)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        return np.where(linear_output > 0, 1, -1)\n",
        "\n",
        "    def train(self, X, y):\n",
        "        num_samples, num_features = X.shape\n",
        "\n",
        "        # Initialize weights and bias\n",
        "        self.weights = np.zeros(num_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Training loop\n",
        "        for _ in range(self.epochs):\n",
        "            for idx, xi in enumerate(X):\n",
        "                update = self.learning_rate * (y[idx] - self.predict(xi))\n",
        "                self.weights += update * xi\n",
        "                self.bias += update\n",
        "\n",
        "# Initialize perceptron model\n",
        "perceptron = Perceptron(learning_rate=0.01, epochs=1000)\n",
        "\n",
        "# Train the model\n",
        "perceptron.train(X_train_aligned, y_train)\n",
        "\n",
        "# Predict on validation data\n",
        "y_pred_val = perceptron.predict(X_val_aligned)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.mean(y_pred_val == y_val)\n",
        "\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv8sjqDorq4T",
        "outputId": "eb1b52bf-ca39-46fe-b1cd-f238cf70493d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8019446956971185"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define a grid of hyperparameters\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "epochs_list = [500, 1000, 2000]\n",
        "\n",
        "best_accuracy = 0\n",
        "best_lr = None\n",
        "best_epochs = None\n",
        "\n",
        "# Grid search for hyperparameter tuning\n",
        "for lr in learning_rates:\n",
        "    for epochs in epochs_list:\n",
        "        perceptron = Perceptron(learning_rate=lr, epochs=epochs)\n",
        "        perceptron.train(X_train_aligned, y_train)\n",
        "        y_pred_val = perceptron.predict(X_val_aligned)\n",
        "        accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_lr = lr\n",
        "            best_epochs = epochs\n",
        "\n",
        "best_lr, best_epochs, best_accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IfbSLEBsB7O",
        "outputId": "a09234da-9ed2-450a-b2ac-35de121f2de1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.1, 500, 0.8243636128698798)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a subset (10%) of the training data\n",
        "subset_size = int(0.1 * X_train_aligned.shape[0])\n",
        "X_train_subset = X_train_aligned[:subset_size]\n",
        "y_train_subset = y_train[:subset_size]\n",
        "\n",
        "best_accuracy = 0\n",
        "best_lr = None\n",
        "best_epochs = None\n",
        "\n",
        "# Grid search for hyperparameter tuning on the subset\n",
        "for lr in learning_rates:\n",
        "    for epochs in epochs_list:\n",
        "        perceptron = Perceptron(learning_rate=lr, epochs=epochs)\n",
        "        perceptron.train(X_train_subset, y_train_subset)\n",
        "        y_pred_val = perceptron.predict(X_val_aligned)\n",
        "        accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_lr = lr\n",
        "            best_epochs = epochs\n",
        "\n",
        "best_lr, best_epochs, best_accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMEB0OrkqzAb",
        "outputId": "588a2212-8628-417b-b301-217371af61ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.01, 2000, 0.7467050006460783)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}